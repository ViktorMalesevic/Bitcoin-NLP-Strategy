{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TWITTER WEBSCRAPPING\n",
    "\n",
    "Here we are going to webscrap the twitter accounts of the top-100 influencers in the cryptocurrency world. The first step is webscrapping the top100 accounts and then all the tweets they perfromed.\n",
    "\n",
    "#### Data Sources:\n",
    "\n",
    "Cryptocurrencies influencer ranking: \"https://cryptoweekly.co/100/\"\n",
    "\n",
    "The following code has been adapted from:\n",
    "https://codeburst.io/a-twitter-analysis-of-the-100-most-influential-people-in-crypto-bb95b2608925\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we load the general packages:\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "def getTwitterHandles():\n",
    "\t# Fill in with url of page which is to be scraped\n",
    "\turl = \"https://cryptoweekly.co/100/\"\n",
    "\n",
    "\t# Retreives and parses page html\n",
    "\tclient = urlopen(url)\n",
    "\tpageHtml = client.read()\n",
    "\tpageSoup = soup(pageHtml, \"html.parser\")\n",
    "\n",
    "\t# Adds all Twitter handles to twitterHandles list\n",
    "\tprofiles = pageSoup.findAll(\"div\", {\"class\":\"testimonial-wrapper\"})\n",
    "\ttwitterHandles = []\n",
    "\tfor person in profiles:\n",
    "\t\ttwitterHandles.append(person.findAll(\"div\",{\"class\":\"author\"}))\n",
    "\tfor i in range(len(twitterHandles)):\n",
    "\t\ttwitterHandles[i]=twitterHandles[i][0].findAll(\"a\")[0].text[1:]\n",
    "\n",
    "\tclient.close()\n",
    "\treturn twitterHandles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets from @VitalikButerin\n",
      "Getting tweets before 1030153145299566592\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 1027019525898682367\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 1017443618473369599\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 1011573593593950207\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 1002007292160569343\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 993679744393732096\n",
      "...1400 tweets downloaded so far\n",
      "Getting tweets before 987397430629945344\n",
      "...1600 tweets downloaded so far\n",
      "Getting tweets before 981095728008257535\n",
      "...1800 tweets downloaded so far\n",
      "Getting tweets before 967393860635697152\n",
      "...2000 tweets downloaded so far\n",
      "Getting tweets before 955487619139416063\n",
      "...2199 tweets downloaded so far\n",
      "Getting tweets before 945322137249648640\n",
      "...2399 tweets downloaded so far\n",
      "Getting tweets before 936784631583477759\n",
      "...2599 tweets downloaded so far\n",
      "Getting tweets before 932512383263633407\n",
      "...2799 tweets downloaded so far\n",
      "Getting tweets before 928820644178927615\n",
      "...2999 tweets downloaded so far\n",
      "Getting tweets before 921713957802512385\n",
      "...3199 tweets downloaded so far\n",
      "Getting tweets before 917022591562297343\n",
      "...3224 tweets downloaded so far\n",
      "Getting tweets before 916827886509744127\n",
      "...3224 tweets downloaded so far\n",
      "Getting tweets from @SatoshiLite\n",
      "Getting tweets before 1020536621148467200\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 1018679560408199168\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 1016936075829231616\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 1011262859093803008\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 1009270439296696319\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 1005946255627804671\n",
      "...1400 tweets downloaded so far\n",
      "Getting tweets before 1001341725988634623\n",
      "...1600 tweets downloaded so far\n",
      "Getting tweets before 998267954566381567\n",
      "...1800 tweets downloaded so far\n",
      "Getting tweets before 992972618557833216\n",
      "...2000 tweets downloaded so far\n",
      "Getting tweets before 989611144657518591\n",
      "...2200 tweets downloaded so far\n",
      "Getting tweets before 986213792022343680\n",
      "...2400 tweets downloaded so far\n",
      "Getting tweets before 982407310365503487\n",
      "...2600 tweets downloaded so far\n",
      "Getting tweets before 979823557889867775\n",
      "...2800 tweets downloaded so far\n",
      "Getting tweets before 978695752456138751\n",
      "...3000 tweets downloaded so far\n",
      "Getting tweets before 974516185503907839\n",
      "...3200 tweets downloaded so far\n",
      "Getting tweets before 970719929807781887\n",
      "...3225 tweets downloaded so far\n",
      "Getting tweets before 970383830497484801\n",
      "...3225 tweets downloaded so far\n",
      "Getting tweets from @brian_armstrong\n",
      "Getting tweets before 1009192218169446399\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 965794155724025855\n",
      "...598 tweets downloaded so far\n",
      "Getting tweets before 935695682819694592\n",
      "...798 tweets downloaded so far\n",
      "Getting tweets before 915105912137801728\n",
      "...998 tweets downloaded so far\n",
      "Getting tweets before 895187474217041919\n",
      "...1197 tweets downloaded so far\n",
      "Getting tweets before 865669949678698496\n",
      "...1397 tweets downloaded so far\n",
      "Getting tweets before 828462024489250816\n",
      "...1597 tweets downloaded so far\n",
      "Getting tweets before 809077918504599551\n",
      "...1797 tweets downloaded so far\n",
      "Getting tweets before 773752673006784511\n",
      "...1997 tweets downloaded so far\n",
      "Getting tweets before 747905273579216895\n",
      "...2197 tweets downloaded so far\n",
      "Getting tweets before 703417486381715456\n",
      "...2396 tweets downloaded so far\n",
      "Getting tweets before 687673049307414527\n",
      "...2596 tweets downloaded so far\n",
      "Getting tweets before 669936229731799039\n",
      "...2796 tweets downloaded so far\n",
      "Getting tweets before 646739732278460415\n",
      "...2994 tweets downloaded so far\n",
      "Getting tweets before 618571345912205312\n",
      "...3194 tweets downloaded so far\n",
      "Getting tweets before 593488320094679039\n",
      "...3238 tweets downloaded so far\n",
      "Getting tweets before 586210441463898112\n",
      "...3238 tweets downloaded so far\n",
      "Getting tweets from @rogerkver\n",
      "Getting tweets before 956177172510773248\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 871715077551931392\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 783110789905297407\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 714506362521137151\n",
      "...999 tweets downloaded so far\n",
      "Getting tweets before 664111817690513408\n",
      "...1199 tweets downloaded so far\n",
      "Getting tweets before 626045320443486207\n",
      "...1398 tweets downloaded so far\n",
      "Getting tweets before 573532601379520511\n",
      "...1593 tweets downloaded so far\n",
      "Getting tweets before 534555236619128831\n",
      "...1793 tweets downloaded so far\n",
      "Getting tweets before 464943421271310335\n",
      "...1993 tweets downloaded so far\n",
      "Getting tweets before 424714274305347583\n",
      "...2193 tweets downloaded so far\n",
      "Getting tweets before 360250281621069823\n",
      "...2393 tweets downloaded so far\n",
      "Getting tweets before 317437945667780607\n",
      "...2593 tweets downloaded so far\n",
      "Getting tweets before 239525501457297407\n",
      "...2791 tweets downloaded so far\n",
      "Getting tweets before 200090126947332095\n",
      "...2963 tweets downloaded so far\n",
      "Getting tweets before 87798894498545663\n",
      "...2963 tweets downloaded so far\n",
      "Getting tweets from @aantonop\n",
      "Getting tweets before 1017818780020461568\n",
      "...398 tweets downloaded so far\n",
      "Getting tweets before 991845909972504575\n",
      "...597 tweets downloaded so far\n",
      "Getting tweets before 984253878756659199\n",
      "...797 tweets downloaded so far\n",
      "Getting tweets before 978307929412485121\n",
      "...996 tweets downloaded so far\n",
      "Getting tweets before 973556191442870272\n",
      "...1196 tweets downloaded so far\n",
      "Getting tweets before 967160225378660351\n",
      "...1396 tweets downloaded so far\n",
      "Getting tweets before 959878955716063231\n",
      "...1595 tweets downloaded so far\n",
      "Getting tweets before 945639784378195967\n",
      "...1794 tweets downloaded so far\n",
      "Getting tweets before 936301765477232640\n",
      "...1993 tweets downloaded so far\n",
      "Getting tweets before 931201766141591552\n",
      "...2193 tweets downloaded so far\n",
      "Getting tweets before 924066319779188735\n",
      "...2392 tweets downloaded so far\n",
      "Getting tweets before 911654434203107327\n",
      "...2589 tweets downloaded so far\n",
      "Getting tweets before 906889927404769279\n",
      "...2789 tweets downloaded so far\n",
      "Getting tweets before 900061180810719232\n",
      "...2988 tweets downloaded so far\n",
      "Getting tweets before 891704197288271872\n",
      "...3187 tweets downloaded so far\n",
      "Getting tweets before 882031139375915007\n",
      "...3225 tweets downloaded so far\n",
      "Getting tweets before 879327196715679743\n",
      "...3225 tweets downloaded so far\n",
      "Getting tweets from @NickSzabo4\n",
      "Getting tweets before 1036829278162235391\n",
      "...398 tweets downloaded so far\n",
      "Getting tweets before 1034311813670694912\n",
      "...592 tweets downloaded so far\n",
      "Getting tweets before 1032888357410332671\n",
      "...792 tweets downloaded so far\n",
      "Getting tweets before 1031707483193004032\n",
      "...992 tweets downloaded so far\n",
      "Getting tweets before 1030321820929421312\n",
      "...1191 tweets downloaded so far\n",
      "Getting tweets before 1028525467471511553\n",
      "...1391 tweets downloaded so far\n",
      "Getting tweets before 1026925941891641343\n",
      "...1590 tweets downloaded so far\n",
      "Getting tweets before 1024942673721876480\n",
      "...1790 tweets downloaded so far\n",
      "Getting tweets before 1016937983612616703\n",
      "...1989 tweets downloaded so far\n",
      "Getting tweets before 1009841384898129924\n",
      "...2187 tweets downloaded so far\n",
      "Getting tweets before 999158177328316416\n",
      "...2384 tweets downloaded so far\n",
      "Getting tweets before 988758325872418816\n",
      "...2583 tweets downloaded so far\n",
      "Getting tweets before 979416602037796865\n",
      "...2780 tweets downloaded so far\n",
      "Getting tweets before 966602232824193023\n",
      "...2979 tweets downloaded so far\n",
      "Getting tweets before 953454233000398847\n",
      "...3178 tweets downloaded so far\n",
      "Getting tweets before 935660205211127807\n",
      "...3226 tweets downloaded so far\n",
      "Getting tweets before 916035561764220927\n",
      "...3226 tweets downloaded so far\n",
      "Getting tweets from @dtapscott\n",
      "Getting tweets before 1004405746073788415\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 968838154680717311\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 937761368396136448\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 914548284580122623\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 884857815386513407\n",
      "...1197 tweets downloaded so far\n",
      "Getting tweets before 856831977504342015\n",
      "...1395 tweets downloaded so far\n",
      "Getting tweets before 841807275845144576\n",
      "...1594 tweets downloaded so far\n",
      "Getting tweets before 821735780322279423\n",
      "...1794 tweets downloaded so far\n",
      "Getting tweets before 806272123878707199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1994 tweets downloaded so far\n",
      "Getting tweets before 796466213010472959\n",
      "...2194 tweets downloaded so far\n",
      "Getting tweets before 786870903174930431\n",
      "...2394 tweets downloaded so far\n",
      "Getting tweets before 772785360044711935\n",
      "...2594 tweets downloaded so far\n",
      "Getting tweets before 764193170431369215\n",
      "...2794 tweets downloaded so far\n",
      "Getting tweets before 755207484000890880\n",
      "...2994 tweets downloaded so far\n",
      "Getting tweets before 749913271705145343\n",
      "...3194 tweets downloaded so far\n",
      "Getting tweets before 746719231010545664\n",
      "...3195 tweets downloaded so far\n",
      "Getting tweets before 746718897399799807\n",
      "...3195 tweets downloaded so far\n",
      "Getting tweets from @gavinandresen\n",
      "Getting tweets before 940643034584186888\n",
      "...398 tweets downloaded so far\n",
      "Getting tweets before 866019623266897921\n",
      "...598 tweets downloaded so far\n",
      "Getting tweets before 831890752653422593\n",
      "...797 tweets downloaded so far\n",
      "Getting tweets before 745687988609388544\n",
      "...996 tweets downloaded so far\n",
      "Getting tweets before 661943242158694399\n",
      "...1196 tweets downloaded so far\n",
      "Getting tweets before 578596808378720255\n",
      "...1396 tweets downloaded so far\n",
      "Getting tweets before 483329212674486271\n",
      "...1596 tweets downloaded so far\n",
      "Getting tweets before 384834338900041727\n",
      "...1796 tweets downloaded so far\n",
      "Getting tweets before 122346621185957887\n",
      "...1850 tweets downloaded so far\n",
      "Getting tweets before 15129517562\n",
      "...1850 tweets downloaded so far\n",
      "Getting tweets from @jihanwu\n",
      "Getting tweets before 946783929041747967\n",
      "...399 tweets downloaded so far\n",
      "Getting tweets before 923242864263303167\n",
      "...598 tweets downloaded so far\n",
      "Getting tweets before 861444961224368127\n",
      "...798 tweets downloaded so far\n",
      "Getting tweets before 704477869653688319\n",
      "...836 tweets downloaded so far\n",
      "Getting tweets before 574981148310274047\n",
      "...836 tweets downloaded so far\n",
      "Getting tweets from @laurashin\n",
      "Getting tweets before 1019003464351961090\n",
      "...399 tweets downloaded so far\n",
      "Getting tweets before 1007629082996207615\n",
      "...599 tweets downloaded so far\n",
      "Getting tweets before 996728375455748096\n",
      "...799 tweets downloaded so far\n",
      "Getting tweets before 981943895817797637\n",
      "...998 tweets downloaded so far\n",
      "Getting tweets before 973923960613056511\n",
      "...1198 tweets downloaded so far\n",
      "Getting tweets before 967125839954366464\n",
      "...1398 tweets downloaded so far\n",
      "Getting tweets before 956579700259766271\n",
      "...1598 tweets downloaded so far\n",
      "Getting tweets before 936481172032335871\n",
      "...1797 tweets downloaded so far\n",
      "Getting tweets before 925502673549385727\n",
      "...1997 tweets downloaded so far\n",
      "Getting tweets before 917956506661695487\n",
      "...2197 tweets downloaded so far\n",
      "Getting tweets before 910183268263137279\n",
      "...2397 tweets downloaded so far\n",
      "Getting tweets before 900509568156934143\n",
      "...2596 tweets downloaded so far\n",
      "Getting tweets before 890994229610151935\n",
      "...2795 tweets downloaded so far\n",
      "Getting tweets before 884418218185641983\n",
      "...2995 tweets downloaded so far\n",
      "Getting tweets before 873542827090657280\n",
      "...3194 tweets downloaded so far\n",
      "Getting tweets before 867010839659806719\n",
      "...3233 tweets downloaded so far\n",
      "Getting tweets before 865761952873795583\n",
      "...3233 tweets downloaded so far\n",
      "Getting tweets from @thomaspower\n",
      "Getting tweets before 1041578653551927295\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 1041305393241247743\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 1040853734664953855\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 1040511329973493759\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 1039867771742498816\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 1039530183492034559\n",
      "...1400 tweets downloaded so far\n",
      "Getting tweets before 1039075219565146111\n",
      "...1600 tweets downloaded so far\n",
      "Getting tweets before 1038310107933749247\n",
      "...1800 tweets downloaded so far\n",
      "Getting tweets before 1037636509887864831\n",
      "...2000 tweets downloaded so far\n",
      "Getting tweets before 1036817864391581695\n",
      "...2200 tweets downloaded so far\n",
      "Getting tweets before 1036105511974961151\n",
      "...2400 tweets downloaded so far\n",
      "Getting tweets before 1035412957180698623\n",
      "...2600 tweets downloaded so far\n",
      "Getting tweets before 1034516538722799616\n",
      "...2800 tweets downloaded so far\n",
      "Getting tweets before 1034041519546753023\n",
      "...3000 tweets downloaded so far\n",
      "Getting tweets before 1033260895621865472\n",
      "...3200 tweets downloaded so far\n",
      "Getting tweets before 1032577764329746437\n",
      "...3236 tweets downloaded so far\n",
      "Getting tweets before 1032571830702428159\n",
      "...3236 tweets downloaded so far\n",
      "Getting tweets from @ErikVoorhees\n",
      "Getting tweets before 1037080030340214783\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 993648932772134911\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 974364402056028159\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 958543763021840383\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 941793119674048511\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 923204454152790020\n",
      "...1399 tweets downloaded so far\n",
      "Getting tweets before 910502089729515519\n",
      "...1599 tweets downloaded so far\n",
      "Getting tweets before 902289190003474432\n",
      "...1799 tweets downloaded so far\n",
      "Getting tweets before 891839284625293312\n",
      "...1999 tweets downloaded so far\n",
      "Getting tweets before 881884121815015424\n",
      "...2199 tweets downloaded so far\n",
      "Getting tweets before 870326980427698175\n",
      "...2399 tweets downloaded so far\n",
      "Getting tweets before 859951983985295361\n",
      "...2598 tweets downloaded so far\n",
      "Getting tweets before 846362806798749695\n",
      "...2798 tweets downloaded so far\n",
      "Getting tweets before 836626939590868993\n",
      "...2997 tweets downloaded so far\n",
      "Getting tweets before 831164970926796802\n",
      "...3195 tweets downloaded so far\n",
      "Getting tweets before 814216797738172416\n",
      "...3233 tweets downloaded so far\n",
      "Getting tweets before 809549879458594817\n",
      "...3233 tweets downloaded so far\n",
      "Getting tweets from @tylerwinklevoss\n",
      "Getting tweets before 944637474613145601\n",
      "...398 tweets downloaded so far\n",
      "Getting tweets before 791654975571169279\n",
      "...596 tweets downloaded so far\n",
      "Getting tweets before 667067280187072512\n",
      "...795 tweets downloaded so far\n",
      "Getting tweets before 608640161547739135\n",
      "...995 tweets downloaded so far\n",
      "Getting tweets before 535160554206552064\n",
      "...1189 tweets downloaded so far\n",
      "Getting tweets before 508634101684137983\n",
      "...1385 tweets downloaded so far\n",
      "Getting tweets before 431902355697963008\n",
      "...1583 tweets downloaded so far\n",
      "Getting tweets before 376533761531596800\n",
      "...1780 tweets downloaded so far\n",
      "Getting tweets before 304379578565160960\n",
      "...1975 tweets downloaded so far\n",
      "Getting tweets before 269573012523720704\n",
      "...2172 tweets downloaded so far\n",
      "Getting tweets before 260943406577098751\n",
      "...2363 tweets downloaded so far\n",
      "Getting tweets before 236880188011585535\n",
      "...2561 tweets downloaded so far\n",
      "Getting tweets before 150653480846106623\n",
      "...2759 tweets downloaded so far\n",
      "Getting tweets before 133387671866322943\n",
      "...2958 tweets downloaded so far\n",
      "Getting tweets before 115980035151761407\n",
      "...3156 tweets downloaded so far\n",
      "Getting tweets before 79173627131596799\n",
      "...3196 tweets downloaded so far\n",
      "Getting tweets before 75767178510598143\n",
      "...3196 tweets downloaded so far\n",
      "Getting tweets from @barrysilbert\n",
      "Getting tweets before 1010159098833367039\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 982337503137972223\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 959539372185047041\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 905863065207492607\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 890022641070985219\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 876034052503089151\n",
      "...1399 tweets downloaded so far\n",
      "Getting tweets before 867734179257225215\n",
      "...1599 tweets downloaded so far\n",
      "Getting tweets before 861218174175506431\n",
      "...1799 tweets downloaded so far\n",
      "Getting tweets before 816649761692549119\n",
      "...1999 tweets downloaded so far\n",
      "Getting tweets before 808377124587503615\n",
      "...2199 tweets downloaded so far\n",
      "Getting tweets before 794509571633151999\n",
      "...2399 tweets downloaded so far\n",
      "Getting tweets before 788136800120438783\n",
      "...2599 tweets downloaded so far\n",
      "Getting tweets before 771377536357892097\n",
      "...2798 tweets downloaded so far\n",
      "Getting tweets before 753716193794686976\n",
      "...2998 tweets downloaded so far\n",
      "Getting tweets before 740147515736088575\n",
      "...3198 tweets downloaded so far\n",
      "Getting tweets before 723572700170588159\n",
      "...3212 tweets downloaded so far\n",
      "Getting tweets before 722551524455550975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...3212 tweets downloaded so far\n",
      "Getting tweets from @TuurDemeester\n",
      "Getting tweets before 1037766829110898693\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 1034769751766126597\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 1031595660150099967\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 1028262924987637759\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 1024422892329680896\n",
      "...1200 tweets downloaded so far\n",
      "Getting tweets before 1019214138936045568\n",
      "...1400 tweets downloaded so far\n",
      "Getting tweets before 1015680343867887616\n",
      "...1600 tweets downloaded so far\n",
      "Getting tweets before 1011457298278027263\n",
      "...1800 tweets downloaded so far\n",
      "Getting tweets before 1008117845228744703\n",
      "...2000 tweets downloaded so far\n",
      "Getting tweets before 1003996102574661632\n",
      "...2200 tweets downloaded so far\n",
      "Getting tweets before 999810295408148479\n",
      "...2400 tweets downloaded so far\n",
      "Getting tweets before 994632762853339135\n",
      "...2600 tweets downloaded so far\n",
      "Getting tweets before 991332946492772352\n",
      "...2800 tweets downloaded so far\n",
      "Getting tweets before 987070363568955391\n",
      "...3000 tweets downloaded so far\n",
      "Getting tweets before 982277184319471615\n",
      "...3200 tweets downloaded so far\n",
      "Getting tweets before 978696558370844677\n",
      "...3216 tweets downloaded so far\n",
      "Getting tweets before 978618629595041791\n",
      "...3216 tweets downloaded so far\n",
      "Getting tweets from @VinnyLingham\n",
      "Getting tweets before 1030444070932439040\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 1023988158118154239\n",
      "...600 tweets downloaded so far\n",
      "Getting tweets before 1016391265091387391\n",
      "...800 tweets downloaded so far\n",
      "Getting tweets before 1010272836248748031\n",
      "...1000 tweets downloaded so far\n",
      "Getting tweets before 1005949386730307583\n",
      "...1199 tweets downloaded so far\n",
      "Getting tweets before 998780412632559615\n",
      "...1399 tweets downloaded so far\n",
      "Getting tweets before 988435459540860928\n",
      "...1599 tweets downloaded so far\n",
      "Getting tweets before 977625447512006655\n",
      "...1799 tweets downloaded so far\n",
      "Getting tweets before 971725046195437567\n",
      "...1998 tweets downloaded so far\n",
      "Getting tweets before 961374578500128767\n",
      "...2198 tweets downloaded so far\n",
      "Getting tweets before 957478715679633409\n",
      "...2398 tweets downloaded so far\n",
      "Getting tweets before 954133705978626047\n",
      "...2597 tweets downloaded so far\n",
      "Getting tweets before 949851561781469183\n",
      "...2795 tweets downloaded so far\n",
      "Getting tweets before 945712820586344449\n",
      "...2995 tweets downloaded so far\n",
      "Getting tweets before 943245380153630719\n",
      "...3194 tweets downloaded so far\n",
      "Getting tweets before 940450966809088000\n",
      "...3219 tweets downloaded so far\n",
      "Getting tweets before 940038195873431552\n",
      "...3219 tweets downloaded so far\n",
      "Getting tweets from @CharlieShrem\n",
      "Getting tweets before 1012309092344516607\n",
      "...400 tweets downloaded so far\n",
      "Getting tweets before 998559976217087999\n",
      "...598 tweets downloaded so far\n",
      "Getting tweets before 979491349631205375\n",
      "...797 tweets downloaded so far\n",
      "Getting tweets before 964647021226483711\n",
      "...997 tweets downloaded so far\n",
      "Getting tweets before 951186181932355584\n",
      "...1197 tweets downloaded so far\n",
      "Getting tweets before 932998600212312065\n",
      "...1396 tweets downloaded so far\n",
      "Getting tweets before 914210191901683711\n",
      "...1591 tweets downloaded so far\n",
      "Getting tweets before 904107365397659647\n",
      "...1791 tweets downloaded so far\n",
      "Getting tweets before 899045728940695552\n",
      "...1991 tweets downloaded so far\n",
      "Getting tweets before 892433154627297282\n",
      "...2190 tweets downloaded so far\n",
      "Getting tweets before 887100993086926850\n",
      "...2390 tweets downloaded so far\n",
      "Getting tweets before 882341738253361151\n",
      "...2590 tweets downloaded so far\n",
      "Getting tweets before 876919718623535104\n",
      "...2789 tweets downloaded so far\n",
      "Getting tweets before 872841839744872447\n",
      "...2989 tweets downloaded so far\n",
      "Getting tweets before 864940456785973249\n",
      "...3189 tweets downloaded so far\n",
      "Getting tweets before 858764336487124992\n",
      "...3230 tweets downloaded so far\n",
      "Getting tweets before 857296953046159364\n",
      "...3230 tweets downloaded so far\n",
      "Getting tweets from @petertoddbtc\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f02385e20d5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mget_all_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-f02385e20d5f>\u001b[0m in \u001b[0;36mget_all_tweets\u001b[1;34m(screen_name)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#save the id of the oldest tweet less one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moldest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malltweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#keep grabbing tweets until there are no tweets left to grab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Modified from: https://gist.github.com/yanofsky/5436496\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# Twitter API credentials (expired, don't even try it)\n",
    "consumer_key = \"ZBNBE0Iu1TwMl57YdlgtzjMAV\"\n",
    "consumer_secret = \"ujm7CSEAdwJlqTrDNDsQvgvjFYfFDhlN741Cu7QavawWyddvHD\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\"\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "\tprint(\"Getting tweets from @\" + str(screen_name))\n",
    "\n",
    "\t#Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\t\n",
    "\t#authorize twitter, initialize tweepy\n",
    "\tauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\tauth.set_access_token(access_key, access_secret)\n",
    "\tapi = tweepy.API(auth)\n",
    "\t\n",
    "\t#initialize a list to hold all the tweepy Tweets\n",
    "\talltweets = []\t\n",
    "\t\n",
    "\t#make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "\tnew_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\t\n",
    "\t#save most recent tweets\n",
    "\talltweets.extend(new_tweets)\n",
    "\t\n",
    "\t#save the id of the oldest tweet less one\n",
    "\toldest = alltweets[-1].id - 1\n",
    "\t\n",
    "\t#keep grabbing tweets until there are no tweets left to grab\n",
    "\twhile len(new_tweets) > 0:\n",
    "\t\tprint (\"Getting tweets before %s\" % (oldest))\n",
    "\t\t\n",
    "\t\t#all subsiquent requests use the max_id param to prevent duplicates\n",
    "\t\tnew_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\t\t\n",
    "\t\t#save most recent tweets\n",
    "\t\talltweets.extend(new_tweets)\n",
    "\t\t\n",
    "\t\t#update the id of the oldest tweet less one\n",
    "\t\toldest = alltweets[-1].id - 1\n",
    "\t\t\n",
    "\t\tprint (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "\t#transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "\touttweets = [[tweet.id_str.encode('utf-8'), tweet.created_at.strftime('%m/%d/%Y'), tweet.text.encode('utf-8')] for tweet in alltweets]\n",
    "\t\n",
    "\t#write the csv\t\n",
    "\twith open('C:/Users/Eric/Python Projects/Bitcoin-NLP-Strategy/Data/Tweets/%s_tweets.csv' % screen_name, 'w') as f:\n",
    "\t\twriter = csv.writer(fdelimiter='|')\n",
    "\t\twriter.writerow([\"id\",\"created_at\",\"text\"])\n",
    "\t\twriter.writerows(outtweets)\n",
    "\t\n",
    "\tpass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\thandles = getTwitterHandles()\n",
    "    # Modify Peter Todd account to the new one, to avoid webscrapping error:\n",
    "    for i in range(len(handles)):\n",
    "        if handles[i] == 'petertoddbtc':\n",
    "            handles[i] = 'peterktodd'\n",
    "\n",
    "\tfor handle in handles:\n",
    "\t\tget_all_tweets(str(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'handleNamePair.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ad75cfddd6c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Creates a datframe with columns: |Name|Twitter Handle|Path To Tweets|\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhandleNameDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"handleNamePair.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0marrayRep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandleNameDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayRep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'handleNamePair.pickle'"
     ]
    }
   ],
   "source": [
    "# Import modules, set styles\n",
    "#from helperScripts import *\n",
    "import csv\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Creates a datframe with columns: |Name|Twitter Handle|Path To Tweets|\n",
    "handleNameDict = pickle.load(open(\"handleNamePair.pickle\", \"rb\"))\n",
    "arrayRep = np.array(list(handleNameDict.items()))\n",
    "df = pd.DataFrame(arrayRep)\n",
    "df = df.rename(columns={0:\"Name\", 1:\"Twitter Handle\"})\n",
    "\n",
    "pathToTweets = []\n",
    "for person in np.array(df[\"Twitter Handle\"]):\n",
    "    pathToTweets.append(\"C:/Users/Eric/Python Projects/Bitcoin-NLP-Strategy/Data/Tweets/\"+str(person)+\"_tweets.csv\")\n",
    "\n",
    "df[\"Path To Tweets\"] = pathToTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'1041867634222936064'</td>\n",
       "      <td>09/18/2018</td>\n",
       "      <td>b'Lighthouse: an open-source Ethereum 2.0 clie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'1041867091601522688'</td>\n",
       "      <td>09/18/2018</td>\n",
       "      <td>b'@adamdavidlong @gmcmullen @rogerkver I think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'1041866610829549568'</td>\n",
       "      <td>09/18/2018</td>\n",
       "      <td>b'@JoelKatz @rogerkver Not sure if tortious in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'1041866234365497345'</td>\n",
       "      <td>09/18/2018</td>\n",
       "      <td>b'@gakonst Please help me check their correctn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1041484529687572480'</td>\n",
       "      <td>09/17/2018</td>\n",
       "      <td>b'@rogerkver Disagree here in practice. Sure, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'1040116690099425282'</td>\n",
       "      <td>09/13/2018</td>\n",
       "      <td>b'Emergent Ventures from @mercatus and @tylerc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'1039847300699324416'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b'RT @avsa: Gemini dollars by themselves are b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'1039846778256801792'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b\"Four months ago I publicly criticized and ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'1039721929270325248'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b'RT @el33th4xor: Happy 10th anniversary of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'1039721907896168450'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b'RT @glenweyl: Activists, policy makers and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'1039697887054053376'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b\"Me: obviously, let's be realistic, the entir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'1039697228984541184'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b\"@DaviddeGruy 1000x gains in *adoption and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'1039696394368348161'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b'What I *actually* said is that, because larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b'1039695944097259521'</td>\n",
       "      <td>09/12/2018</td>\n",
       "      <td>b'To be clear, I never said that there is \"no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'1039664741944188929'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@matthewde_silva @joonian I agree cryptocurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b'1039664434979921920'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b\"@matthewde_silva @joonian And the SoV use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b'1039664201919164417'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@matthewde_silva @joonian Lack of use cases:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b'1039549336277770240'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'RT @matthewdif: I just published \\xe2\\x80\\x9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b'1039548700702339072'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'Great to see ongoing progress on Constantino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b'1039548596775833600'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b\"@udiWertheimer @joonian @matthewde_silva Oh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b'1039547330934915073'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@udiWertheimer @vasilipoupkine1 @joonian @ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b'1039546632658804736'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@udiWertheimer @joonian @matthewde_silva Als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'1039546248221474816'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@udiWertheimer @joonian @matthewde_silva Why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'1039544589286178816'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b\"@udiWertheimer @joonian @matthewde_silva Als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b'1039543849079599105'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@udiWertheimer @joonian @matthewde_silva Sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b'1039543621769342976'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@thepowerfulHRV @sellxxl @joonian @matthewde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'1039541581399740417'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'@HelpBinance @joonian @matthewde_silva Umm.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b'1039541096420798470'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b\"@chrisbelltoken @joonian @matthewde_silva Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b'1039540811610738688'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b'RT @VitalikButerin: @joonian @matthewde_silv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b'1039540772809236481'</td>\n",
       "      <td>09/11/2018</td>\n",
       "      <td>b\"@udiWertheimer @joonian @matthewde_silva Oh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>b'917388376596111361'</td>\n",
       "      <td>10/09/2017</td>\n",
       "      <td>b'Ethereum DEV Roundup #6, featuring Casper, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>b'917387306734043136'</td>\n",
       "      <td>10/09/2017</td>\n",
       "      <td>b'@SeamanReal @TaylorGerring @IOHK_Charles htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>b'917320815049293824'</td>\n",
       "      <td>10/09/2017</td>\n",
       "      <td>b'@tPmi51LXdTtkMLS Not slow at all. I don\\'t g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>b'917285892091297793'</td>\n",
       "      <td>10/09/2017</td>\n",
       "      <td>b\"@virgilgr @StopAndDecrypt @ProfFaustus I gue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>b'917022591562297344'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@eshioji Because it's not really disintermed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>b'917022455394217987'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@eshioji Except this is one case where disin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>b'917004834296889344'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@shenchris_c \\xe5\\xa6\\x82\\xe6\\x9e\\x9c\\xe6\\xb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>b'916933292309471232'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@mrboson0 https://t.co/f8iSAcraz9'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>b'916928255617245185'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@AlekseiArhipov https://t.co/N1Ysww4Jgp'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>b'916928065862848512'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@PumpyBrewster @anondran I sold to donate as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>b'916927314700787712'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@RainDogDance I'm speaking about crypto-cryp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>b'916926998571814912'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@anondran I sold $6k of OMG on ED last week,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>b'916926487172968448'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"Decentralized exchange: no setup required, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>b'916926266602868736'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'Centralized exchange: register account -&amp;gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>b'916926167986339841'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'Rather, it is in user convenience for regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>b'916926001262755840'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'The main niche for decentralized exchange is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>b'916925813639057408'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@tPmi51LXdTtkMLS That requires setting up an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>b'916924298660425728'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@WillemKadijk It'll get there with scale.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>b'916923993252233217'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@Hague555 Last week. I thought its usability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>b'916920867807944705'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'I think the https://t.co/X1GnJmkC5U model fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>b'916920330861428736'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"My response to cryptocoinsnews: no, I'm not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>b'916860512968753152'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@bitcoin3000 @TomZarebczan @zooko @nikitab I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>b'916859605807915009'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@bitcoin3000 @TomZarebczan @zooko @nikitab 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>b'916859178223730689'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@muradtariq_tk Decentralized insurance *is* ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>b'916858631043170305'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@tezosevangelist @BTC4USD @TomZarebczan @zoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>b'916856614233112576'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"... as an endorsement of any particular proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>b'916856310917824513'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"Yes, I'm an advisor of wetrust. No, I do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>b'916830857096077312'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b'@VladZamfir @virgilgr @StopAndDecrypt @ProfF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>b'916828013584453633'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@virgilgr @StopAndDecrypt @ProfFaustus And I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>b'916827886509744128'</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>b\"@virgilgr @StopAndDecrypt @ProfFaustus I'd s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3224 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  created_at  \\\n",
       "0     b'1041867634222936064'  09/18/2018   \n",
       "1     b'1041867091601522688'  09/18/2018   \n",
       "2     b'1041866610829549568'  09/18/2018   \n",
       "3     b'1041866234365497345'  09/18/2018   \n",
       "4     b'1041484529687572480'  09/17/2018   \n",
       "5     b'1040116690099425282'  09/13/2018   \n",
       "6     b'1039847300699324416'  09/12/2018   \n",
       "7     b'1039846778256801792'  09/12/2018   \n",
       "8     b'1039721929270325248'  09/12/2018   \n",
       "9     b'1039721907896168450'  09/12/2018   \n",
       "10    b'1039697887054053376'  09/12/2018   \n",
       "11    b'1039697228984541184'  09/12/2018   \n",
       "12    b'1039696394368348161'  09/12/2018   \n",
       "13    b'1039695944097259521'  09/12/2018   \n",
       "14    b'1039664741944188929'  09/11/2018   \n",
       "15    b'1039664434979921920'  09/11/2018   \n",
       "16    b'1039664201919164417'  09/11/2018   \n",
       "17    b'1039549336277770240'  09/11/2018   \n",
       "18    b'1039548700702339072'  09/11/2018   \n",
       "19    b'1039548596775833600'  09/11/2018   \n",
       "20    b'1039547330934915073'  09/11/2018   \n",
       "21    b'1039546632658804736'  09/11/2018   \n",
       "22    b'1039546248221474816'  09/11/2018   \n",
       "23    b'1039544589286178816'  09/11/2018   \n",
       "24    b'1039543849079599105'  09/11/2018   \n",
       "25    b'1039543621769342976'  09/11/2018   \n",
       "26    b'1039541581399740417'  09/11/2018   \n",
       "27    b'1039541096420798470'  09/11/2018   \n",
       "28    b'1039540811610738688'  09/11/2018   \n",
       "29    b'1039540772809236481'  09/11/2018   \n",
       "...                      ...         ...   \n",
       "3194   b'917388376596111361'  10/09/2017   \n",
       "3195   b'917387306734043136'  10/09/2017   \n",
       "3196   b'917320815049293824'  10/09/2017   \n",
       "3197   b'917285892091297793'  10/09/2017   \n",
       "3198   b'917022591562297344'  10/08/2017   \n",
       "3199   b'917022455394217987'  10/08/2017   \n",
       "3200   b'917004834296889344'  10/08/2017   \n",
       "3201   b'916933292309471232'  10/08/2017   \n",
       "3202   b'916928255617245185'  10/08/2017   \n",
       "3203   b'916928065862848512'  10/08/2017   \n",
       "3204   b'916927314700787712'  10/08/2017   \n",
       "3205   b'916926998571814912'  10/08/2017   \n",
       "3206   b'916926487172968448'  10/08/2017   \n",
       "3207   b'916926266602868736'  10/08/2017   \n",
       "3208   b'916926167986339841'  10/08/2017   \n",
       "3209   b'916926001262755840'  10/08/2017   \n",
       "3210   b'916925813639057408'  10/08/2017   \n",
       "3211   b'916924298660425728'  10/08/2017   \n",
       "3212   b'916923993252233217'  10/08/2017   \n",
       "3213   b'916920867807944705'  10/08/2017   \n",
       "3214   b'916920330861428736'  10/08/2017   \n",
       "3215   b'916860512968753152'  10/08/2017   \n",
       "3216   b'916859605807915009'  10/08/2017   \n",
       "3217   b'916859178223730689'  10/08/2017   \n",
       "3218   b'916858631043170305'  10/08/2017   \n",
       "3219   b'916856614233112576'  10/08/2017   \n",
       "3220   b'916856310917824513'  10/08/2017   \n",
       "3221   b'916830857096077312'  10/08/2017   \n",
       "3222   b'916828013584453633'  10/08/2017   \n",
       "3223   b'916827886509744128'  10/08/2017   \n",
       "\n",
       "                                                   text  \n",
       "0     b'Lighthouse: an open-source Ethereum 2.0 clie...  \n",
       "1     b'@adamdavidlong @gmcmullen @rogerkver I think...  \n",
       "2     b'@JoelKatz @rogerkver Not sure if tortious in...  \n",
       "3     b'@gakonst Please help me check their correctn...  \n",
       "4     b'@rogerkver Disagree here in practice. Sure, ...  \n",
       "5     b'Emergent Ventures from @mercatus and @tylerc...  \n",
       "6     b'RT @avsa: Gemini dollars by themselves are b...  \n",
       "7     b\"Four months ago I publicly criticized and ad...  \n",
       "8     b'RT @el33th4xor: Happy 10th anniversary of th...  \n",
       "9     b'RT @glenweyl: Activists, policy makers and a...  \n",
       "10    b\"Me: obviously, let's be realistic, the entir...  \n",
       "11    b\"@DaviddeGruy 1000x gains in *adoption and re...  \n",
       "12    b'What I *actually* said is that, because larg...  \n",
       "13    b'To be clear, I never said that there is \"no ...  \n",
       "14    b'@matthewde_silva @joonian I agree cryptocurr...  \n",
       "15    b\"@matthewde_silva @joonian And the SoV use ca...  \n",
       "16    b'@matthewde_silva @joonian Lack of use cases:...  \n",
       "17    b'RT @matthewdif: I just published \\xe2\\x80\\x9...  \n",
       "18    b'Great to see ongoing progress on Constantino...  \n",
       "19    b\"@udiWertheimer @joonian @matthewde_silva Oh ...  \n",
       "20    b'@udiWertheimer @vasilipoupkine1 @joonian @ma...  \n",
       "21    b'@udiWertheimer @joonian @matthewde_silva Als...  \n",
       "22    b'@udiWertheimer @joonian @matthewde_silva Why...  \n",
       "23    b\"@udiWertheimer @joonian @matthewde_silva Als...  \n",
       "24    b'@udiWertheimer @joonian @matthewde_silva Sur...  \n",
       "25    b'@thepowerfulHRV @sellxxl @joonian @matthewde...  \n",
       "26    b'@HelpBinance @joonian @matthewde_silva Umm.....  \n",
       "27    b\"@chrisbelltoken @joonian @matthewde_silva Am...  \n",
       "28    b'RT @VitalikButerin: @joonian @matthewde_silv...  \n",
       "29    b\"@udiWertheimer @joonian @matthewde_silva Oh ...  \n",
       "...                                                 ...  \n",
       "3194  b'Ethereum DEV Roundup #6, featuring Casper, B...  \n",
       "3195  b'@SeamanReal @TaylorGerring @IOHK_Charles htt...  \n",
       "3196  b'@tPmi51LXdTtkMLS Not slow at all. I don\\'t g...  \n",
       "3197  b\"@virgilgr @StopAndDecrypt @ProfFaustus I gue...  \n",
       "3198  b\"@eshioji Because it's not really disintermed...  \n",
       "3199  b'@eshioji Except this is one case where disin...  \n",
       "3200  b'@shenchris_c \\xe5\\xa6\\x82\\xe6\\x9e\\x9c\\xe6\\xb...  \n",
       "3201               b'@mrboson0 https://t.co/f8iSAcraz9'  \n",
       "3202         b'@AlekseiArhipov https://t.co/N1Ysww4Jgp'  \n",
       "3203  b'@PumpyBrewster @anondran I sold to donate as...  \n",
       "3204  b\"@RainDogDance I'm speaking about crypto-cryp...  \n",
       "3205  b'@anondran I sold $6k of OMG on ED last week,...  \n",
       "3206  b\"Decentralized exchange: no setup required, i...  \n",
       "3207  b'Centralized exchange: register account -&gt;...  \n",
       "3208  b'Rather, it is in user convenience for regula...  \n",
       "3209  b'The main niche for decentralized exchange is...  \n",
       "3210  b\"@tPmi51LXdTtkMLS That requires setting up an...  \n",
       "3211       b\"@WillemKadijk It'll get there with scale.\"  \n",
       "3212  b\"@Hague555 Last week. I thought its usability...  \n",
       "3213  b'I think the https://t.co/X1GnJmkC5U model fo...  \n",
       "3214  b\"My response to cryptocoinsnews: no, I'm not ...  \n",
       "3215  b\"@bitcoin3000 @TomZarebczan @zooko @nikitab I...  \n",
       "3216  b'@bitcoin3000 @TomZarebczan @zooko @nikitab 6...  \n",
       "3217  b'@muradtariq_tk Decentralized insurance *is* ...  \n",
       "3218  b'@tezosevangelist @BTC4USD @TomZarebczan @zoo...  \n",
       "3219  b\"... as an endorsement of any particular proj...  \n",
       "3220  b\"Yes, I'm an advisor of wetrust. No, I do not...  \n",
       "3221  b'@VladZamfir @virgilgr @StopAndDecrypt @ProfF...  \n",
       "3222  b\"@virgilgr @StopAndDecrypt @ProfFaustus And I...  \n",
       "3223  b\"@virgilgr @StopAndDecrypt @ProfFaustus I'd s...  \n",
       "\n",
       "[3224 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a unified dataset:\n",
    "mt = pd.DataFrame(columns = [\"Name\", \"id\", \"created_at\", \"text\"])\n",
    "\n",
    "for handle in handles:\n",
    "    df = pd.read_csv('C:/Users/Eric/Python Projects/Bitcoin-NLP-Strategy/Data/Tweets/'+str(handle)+\"_tweets.csv\")\n",
    "    mt = mt.append(df)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, id, created_at, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt = pd.DataFrame(columns = [\"Name\", \"id\", \"created_at\", \"text\"])\n",
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
